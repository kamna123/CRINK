#define _NTHREAD 512
#define _NBLOCK 65535
#include<cuda.h>

__global__ void _AFFINE_KERNEL(int* ,int ,int ,int ,int ,int ,int );

#include<stdio.h>
#include<stdlib.h>
int main()
{
    int A[100],j;
    for(i=0;i<100;i++)
    {
        A[i]=2*i;
    }
	int _SZ_A_1 = 100;
	int *_DEV_A;
	cudaMalloc((void**) &_DEV_A, sizeof(int)*_SZ_A_1);
	cudaMemcpy(_DEV_A, A, sizeof(int)*_SZ_A_1, cudaMemcpyHostToDevice);
	int _NUM_THREADS = 100;
	float _NUM_BLOCKS=1;
	int _NUM_TILE=1;
	dim3 _THREADS(512);
	dim3 _BLOCKS(1);
	if(_NUM_THREADS < _NTHREAD)
	{
		_THREADS.x=_NUM_THREADS;
	}
	else {
		 _THREADS.x=_NTHREAD;
		_NUM_BLOCKS=(_NUM_THREADS % _NTHREAD == 0)?(_NUM_THREADS/_NTHREAD):((_NUM_THREADS/_NTHREAD)+1);
		if(_NUM_BLOCKS<_NBLOCK)
			_BLOCKS.x=_NUM_BLOCKS;
		else {
			_BLOCKS.x=_NBLOCK;
			int temp=_NUM_BLOCKS;
			_NUM_TILE=(temp % _NBLOCK == 0)?(_NUM_BLOCKS/_NBLOCK):((_NUM_BLOCKS/_NBLOCK)+1);
		}
	}
	int _CUDA_TILE;
	for(j=0;j<=99;j+=100)
	for(_CUDA_TILE=0;_CUDA_TILE<_NUM_TILE;_CUDA_TILE++)
	{		_AFFINE_KERNEL<<<_BLOCKS,_THREADS>>>(_DEV_A, _SZ_A_1, 1, j, 0, 99, _CUDA_TILE);
		cudaDeviceSynchronize();
	}	cudaMemcpy(A, _DEV_A, sizeof(int)*_SZ_A_1, cudaMemcpyDeviceToHost);
	cudaFree(_DEV_A);
    return 0;
}



__global__ void _AFFINE_KERNEL(int* A,int _SZ_A_1,int phi_count, int CUDA_j, int CUDA_L_j,int CUDA_U_j, int _CUDA_TILE)
{
	int j = gridDim.x*blockDim.x*_CUDA_TILE + blockDim.x*blockIdx.x + threadIdx.x;
	if((CUDA_j<=j)&&(j<(CUDA_j+100))&&(j<=CUDA_U_j)){
		A[1+j]=A[1+j+100]+10;
}}

